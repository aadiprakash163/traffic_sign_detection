{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traffic sign recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### The steps of this project are the following  \n",
    "1). Load Data from the pickle file  \n",
    "2). Visualization of the data provided  \n",
    "3). Preprocessing of dataset  \n",
    "4). Model architecture  \n",
    "5). Train, Validate and Test the model  \n",
    "6). Find accuracy of trained model on test images  \n",
    "7). Test model on new images  \n",
    "8). Summarize model's performnce on new images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and visualizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset provided consists of three pickle files one each for training, testing and validation purpose. They are loaded by opening them in Readbinary mode. There are 34799 training examples, 4410 validation examples and 12630 testing examples.\n",
    "These examples or images belong to one of the 43 classes present in the dataset. However, number of datasets for each class is not same. Histogram below depicts distribution of training examples among different classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Histogram](hist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Only preprocessing step that i have performed is normalization. I am not converting images to grayscale because i think having three channels can be useful for traffic sign classifications problems. For instance, if we consider classification of traffic light status, then having the RGB channels is mandatory. Also precautionary and warning signs have different coloring scheme and by using three channels we can also have an idea about how crucial that traffic sign is.\n",
    "\n",
    "* Normalisation is done because of the fact that it scales the data in the range 0 to 1 and in this range, activation functions like logsig and tansig has maximum sensitivity so it leads to better convergence of learning. Though no such function is used in this project, it will still improve the learning curve\n",
    "\n",
    "* The training data is also shuffled because dataset provided is grouped according to their classes and training for one class at one time and other at other time will lead to distortions in learning and will not be a good strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Images before and after normalization](NormCompare.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The neural network used is a 4-layer Convolutional Neural Network.\n",
    "* It consists of two convolution layer (feature extraction) followed by two fully connected layers (ReLU activation).\n",
    "* Both the convolutional layers(l1 and l2) use a 3X3 filter as their receptive field. First layer's output have 32 channels whereas second convolutional layer outputs 64 channels.\n",
    "* Both convolutional layers are followed by ReLU and Maxpool with kernel size of 2.\n",
    "* Convolutional layers are followed by 1 fully connected layer(fc) with 1024 nodes.\n",
    "* Connection between l2 and fc have a dropout rate of 0.75.\n",
    "* fc gives 43 outputs each corresponding to 43 classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing of model\n",
    "\n",
    "Training specifics and hyperparameters:\n",
    "* Learning rate: 0.001\n",
    "* Minimum validation accuracy: 0.95\n",
    "* Optimizer used: Adam optimizer\n",
    "* Batch size : 128\n",
    "* Convolution layer kernel size: 3X3\n",
    "* Padding: VALID\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adam optimizer is used because it controls learning rate by itself and also use momentum while learning.\n",
    "The Neural network used has same architecture as that of lenet. At first learning was done using unprocessed images and untuned hyper parameters, still it generated fairly good results. I could get validation accuracy of about 0.85 in under 50 epochs. Though learning initial errors were high, they seemed to decrease with every epochs.\n",
    "Later on using normalised images, convergence got faster and tuning of hyper parameters brought required epochs to around 50 which were earlier around 400. An interesting thing that i noticed was that with proper tuning of hyper parameters we can get a very good leap at the first epoch itself. I am consistently getting around 0.65 to 0.70 accuracy at first epoch itself. But still, there is room for a lot of improvement because the learning stagnates after around 10 epochs and further improvement is very slow and oscilatory in nature.\n",
    "Minimum required accuracy is set to 0.95 and iterations are done untill model is not trained to that level i.e. number of epochs is not a hyperparameter here. Details of model training are given below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Number of epochs: 56  \n",
    "* Validation accuracy: 0.951\n",
    "* Test accuracy: 0.945  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model on new images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For testing the model with unseen images, 5 images were downloaded from internet. Following test images were downloaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Test_images/1.jpg)\n",
    "![title](Test_images/2.jpg)\n",
    "![title](Test_images/3.jpg)\n",
    "![title](Test_images/4.jpg)\n",
    "![title](Test_images/5.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these images are not 32X32, we have to resize them first, normalize and then apply to our classification model.  \n",
    "Model performance on new images is poor. Only 1 image out of the five images is correctly classified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible improvements to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier did not work well on new images that means we could not get good generalized training. One possible reason might be unequal distribution of training samples for different classes. As some of the classes have much more samples, training turn out to biased towards those samples and new images are not properly classified. This is evident in classification of new images. Highest probability answers are corresponding to classes with large number of samples.  \n",
    "To improve performance of our neural network, we can augment the given dataset with some additional self generated dataset. This will result in training for each class equally."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:SDCndP1]",
   "language": "python",
   "name": "conda-env-SDCndP1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
